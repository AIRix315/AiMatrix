# V0.4.0 架构对齐方案 - 实施计划

> **创建时间**: 2026-01-07
> **目标**：审查并调整 `docs/Plan/V0.4.0-Architecture-Alignment.md`，确保与项目现有架构和讨论共识对齐
> **状态**：✅ **方案文档已完全更新，待用户确认后实施**

## 本次更新内容摘要

架构文档 `V0.4.0-Architecture-Alignment.md` 已完成以下更新：

1. **Section 5.3 WorkflowExecutor.ts 修正**
   - 识别 `executeStage4` 缺少视频生成调用
   - 添加完整修正方案代码

2. **Section 3.3 NovelVideoAPIService.ts 详细问题清单**
   - 按行号列出 8 处需修改的硬编码问题

3. **Section 4.4 模型名称映射机制**（新增）
   - 说明 Adapter 层负责供应商特定名称映射
   - 包含完整映射流程和示例代码

4. **Section 5.1 阀门配置修正**
   - Stage 4 输出改为 `["storyboardImages", "videoSegments"]`

5. **Section 8 文件清单更新**
   - WorkflowExecutor.ts 从"保持不变"改为"需修改"
   - 修改文件数从 6 个增至 7 个

---

## 零、N8N 工作流完整性验证

### 0.1 N8N 工作流数据流

```
输入: 小说文本 + 艺术风格
         │
         v
┌─────────────────────────────────────────────────────────┐
│  Stage 1: 场景分解 + 角色识别                            │
│  - 使用: DeepSeek Chat (LLM)                            │
│  - 产出: scenes[], characters[]                         │
└─────────────────────────────────────────────────────────┘
         │
         v
┌─────────────────────────────────────────────────────────┐
│  Stage 2: 角色/场景图片生成（并行）                      │
│  - 使用: Z-Image Turbo (文生图，异步)                   │
│  - 产出: characterImages[], sceneImages[]               │
└─────────────────────────────────────────────────────────┘
         │
         v
┌─────────────────────────────────────────────────────────┐
│  Stage 2.5: 场景摘要生成                                │
│  - 使用: DeepSeek Chat (LLM)                            │
│  - 产出: sceneSummaries[] (每场景100字摘要)             │
└─────────────────────────────────────────────────────────┘
         │
         v
┌─────────────────────────────────────────────────────────┐
│  Stage 3: 分镜脚本生成（4步AI链式调用）                  │
│  - 使用: DeepSeek Chat (LLM)                            │
│  - 产出: storyboards[] (图片分镜 + 视频分镜)            │
└─────────────────────────────────────────────────────────┘
         │
         v
┌─────────────────────────────────────────────────────────┐
│  Stage 4: 资产生成                                      │
│  ├─ 分镜图片: Nano Banana Pro I2I (图生图，同步)        │
│  └─ 视频片段: Sora 2 (图生视频，异步)                   │
│  - 产出: storyboardImages[], videoSegments[]            │
└─────────────────────────────────────────────────────────┘
         │
         v
输出: 角色图片 + 场景图片 + 分镜漫画 + 视频片段(10秒/段)
```

### 0.2 现有实现 vs N8N 对比

| 阶段 | N8N | MATRIX 实现 | 状态 |
|------|-----|-------------|------|
| Stage 1 | ✅ | ChapterService.extractScenesAndCharacters | ✅ 已实现 |
| Stage 2 | ✅ | ResourceService.generateSceneImages/CharacterImages | ✅ 已实现 |
| Stage 2.5 | ✅ | StoryboardService.generateSceneSummaries | ✅ 已实现 |
| Stage 3 | ✅ | StoryboardService.generateContextualScript | ✅ 已实现 |
| Stage 4 图片 | ✅ | ResourceService.generateI2IImages | ✅ 已实现 |
| **Stage 4 视频** | ✅ | **缺失** | ⚠️ **需补充** |

### 0.3 供应商切换能力验证

**问题**：修改后能否将 JiekouAI 切换为 T8Star 或本地 ComfyUI？

**验证结论**：✅ **可以**

**切换机制**：
```
1. 插件配置只指定模型名称:
   { "models": { "videoGeneration": "sora-2" } }

2. APIManager.callModel() 查找支持该模型的 Provider:
   providers.filter(p => p.models.includes("sora-2"))

3. 根据 Provider.apiFormat 选择 Adapter:
   - JiekouAI → AsyncPollingAdapter
   - T8Star → OpenAICompatibleAdapter
   - ComfyUI → ComfyUIWorkflowAdapter

4. Adapter 执行具体 API 调用，处理格式差异
```

**本地模型支持**：
- ComfyUI 本地: 注册 Provider, apiFormat='comfyui-workflow'
- Ollama 本地: 注册 Provider, apiFormat='openai-compatible'

### 0.4 发现的问题（已修正）

1. **视频生成方法已存在，但未被调用**
   - `NovelVideoAPIService.generateStoryboardVideo()` 已实现（第300-376行）
   - 问题：`WorkflowExecutor.executeStage4` 没有调用视频生成
   - 修复：在 executeStage4 中添加视频生成调用

2. **模型名称映射机制**（用户确认）
   - 插件层只关心功能类型，不关心具体模型名称
   - 用户在 Settings 选择供应商 → 刷出模型列表 → 选定一个
   - Adapter 层负责供应商特定的模型名称映射
   - 例：用户选 `sora-2`，JiekouAI Adapter 映射为 `sora-2-video-reverse`

3. **callI2IAPI 硬编码问题**（确认）
   - 第467行直接调用 `JiekouAIProvider.imageToImage`
   - 需要改为通过 `callModel()` 调用

### 0.5 NovelVideoAPIService.ts 详细问题清单

| 行号 | 问题 | 修改方式 |
|------|------|---------|
| 11 | `import { JiekouAIProvider }` | 删除 |
| 52-73 | `registerProviders()` 注册 JiekouAI | 删除整个方法 |
| 99-115 | 硬编码默认 Provider ID | 改为从配置读取模型名称 |
| 167 | `if (providerId === 't8star-image')` | 改为 `callModel()` |
| 254 | `if (providerId === 't8star-image')` | 改为 `callModel()` |
| 343 | `if (providerId === 't8star-video')` | 改为 `callModel()` |
| 430 | `callRunningHubTTS` (不存在的方法) | 删除或抛出明确错误 |
| 467 | `JiekouAIProvider.imageToImage` 直接调用 | 改为 `callModel()` |

### 0.6 WorkflowExecutor.ts 问题

| 位置 | 问题 | 修改方式 |
|------|------|---------|
| executeStage4 | 只生成分镜图片，缺少视频生成 | 添加 `generateStoryboardVideos()` 调用 |

---

## 一、方案需要调整的内容

### 1.1 适配器命名调整

**原方案**：
```
src/main/adapters/JiekouCustomAdapter.ts
```

**调整为**：
```
src/main/adapters/AsyncPollingAdapter.ts
```

**理由**：不应出现供应商名称，按功能特性命名

---

### 1.2 与现有架构整合说明

**原方案遗漏**：未说明新 Adapter 层与现有 ProviderHub/ProviderRouter/ProviderRegistry 的关系

**需要补充**：

```
Adapter 层定位：作为 API 调用的实现层

职责分工：
- ProviderRegistry: Provider 实例注册和查询（保留）
- ProviderRouter: 操作类型到 Provider 的路由（保留，但路由到 Adapter）
- ProviderHub: 统一门面（保留）
- Adapter: 具体的 API 调用格式适配（新增）
- APIManager: Provider 配置管理 + callModel 统一入口（扩展）

调用链：
  插件 → APIManager.callModel()
       → 查询支持该模型的 Provider
       → 根据 Provider.apiFormat 选择 Adapter
       → Adapter 执行具体 API 调用
```

---

### 1.3 硬编码方法处理策略

**原方案**：直接新增 callModel()，未提及现有方法处理

**需要补充**：

```
阶段 1: 备份（在删除任何代码前）
- APIManager.ts 中的 callT8StarImage() → 备份为 .bak 或注释保留
- APIManager.ts 中的 callT8StarVideo() → 备份为 .bak 或注释保留
- APIManager.ts 中的 callRunningHubWorkflow() → 保留（工作流模式不同）

阶段 2: 抽象
- 将 callT8StarImage 的逻辑抽象为 OpenAICompatibleAdapter.callImageGeneration()
- 将 callT8StarVideo 的逻辑抽象为 OpenAICompatibleAdapter.callVideoGeneration()
- 将轮询逻辑抽象为 AsyncPollingAdapter（支持 Jiekou 等异步 API）

阶段 3: 替换
- callModel() 调用 Adapter
- 插件改用 callModel()
- 标记旧方法为 @deprecated

阶段 4: 清理（后续版本）
- 确认无调用后删除 @deprecated 方法
```

---

### 1.4 插件层删除范围修正

**原方案描述**：
- 删除 JiekouAIProvider.ts（√ 正确）
- 删除 NovelVideoAPIService.ts 中的 JiekouAIProvider 导入（× 实际上是死代码引用）

**修正为**：

```
需要删除的内容：

1. 死代码删除
   - plugins/official/novel-to-video/src/services/providers/ 整个目录
     （JiekouAIProvider.ts 从未被调用，是遗留死代码）

2. 冗余配置删除
   - default-config.json 中的 workflow.providers 部分（第31-46行）
     （与顶层 providers 配置重复且从未使用）

3. 孤立方法删除
   - NovelVideoAPIService.ts 中调用 callRunningHubTTS() 的代码
     （该方法在 APIManager 中不存在，会导致运行时错误）

需要修改的内容：

1. NovelVideoAPIService.ts
   - 移除第102-114行的硬编码默认 Provider ID
   - 将 if (providerId === 't8star-image') 检查改为通用调用

2. default-config.json
   - 简化为只保留模型配置（符合"模型优先"原则）
```

---

### 1.5 类型定义补充

**原方案**：只提到扩展 APIProviderConfig

**需要补充**：

```
需要检查 src/shared/types/provider.ts 中的 IProvider 接口：
- 现有 IProvider 只有 checkAvailability() 方法
- 可能需要添加执行方法的签名
- 或者：Adapter 不依赖 IProvider，直接使用 APIProviderConfig
```

---

## 二、调整后的实施顺序

### P0 阶段：系统层基础

1. **类型扩展**
   - 修改 `src/shared/types/api.ts`
   - 添加 `apiFormat` 字段到 APIProviderConfig
   - 验证：npm run build 无错误

2. **适配器层创建**
   - 创建 `src/main/adapters/BaseAdapter.ts`
   - 创建 `src/main/adapters/OpenAICompatibleAdapter.ts`
   - 创建 `src/main/adapters/AsyncPollingAdapter.ts`（原 JiekouCustomAdapter）
   - 创建 `src/main/adapters/ComfyUIWorkflowAdapter.ts`
   - 创建 `src/main/adapters/index.ts`（导出）

3. **APIManager 扩展**
   - 备份现有 callT8StarImage/callT8StarVideo 方法
   - 新增 adapters 成员变量
   - 新增 registerAdapters() 方法
   - 新增 callModel() 方法
   - 标记旧方法为 @deprecated

### P0 阶段：插件层清理

4. **删除死代码**
   - 删除 `plugins/official/novel-to-video/src/services/providers/` 目录
   - 验证：目录不存在

5. **配置简化**
   - 修改 `default-config.json`，移除 workflow.providers
   - 简化为模型配置
   - 验证：无 providerId 字段

6. **NovelVideoAPIService 重构**
   - 移除硬编码 Provider ID
   - 改用 apiManager.callModel()
   - 移除 callRunningHubTTS 相关代码（或抛出明确错误）

### P1 阶段：服务扩展

7. **WorkflowExecutor 修正**
   - 修改 `executeStage4()` 方法
   - 添加视频生成调用 `generateStoryboardVideos()`
   - 更新返回的 outputs 包含 `videoSegments`

8. **StoryboardService 扩展**
   - 新增 generateSceneSummaries() 方法
   - 修改 generateStoryboard() 签名

9. **ResourceService 扩展**
   - 新增 generateI2IImages() 方法（使用 callModel）
   - 新增 generateStoryboardVideo() 方法（使用 callModel）

### P1 阶段：验收测试

10. **功能验收**
    - callModel() 成功路由到正确 Provider
    - 切换 Provider 后插件自动使用新配置
    - N8N 工作流 5 阶段完整执行（含视频生成）

11. **代码验收**
    - 插件目录无 providers 子目录
    - 无硬编码供应商 ID
    - 适配器命名无供应商名称

---

## 三、关键文件清单

### 新增文件（4个）
```
src/main/adapters/BaseAdapter.ts
src/main/adapters/OpenAICompatibleAdapter.ts
src/main/adapters/AsyncPollingAdapter.ts        ← 原 JiekouCustomAdapter
src/main/adapters/ComfyUIWorkflowAdapter.ts
```

### 删除文件/目录
```
plugins/official/novel-to-video/src/services/providers/  ← 整个目录
```

### 修改文件（7个）
```
src/shared/types/api.ts
src/main/services/APIManager.ts
plugins/official/novel-to-video/default-config.json
plugins/official/novel-to-video/src/services/NovelVideoAPIService.ts
plugins/official/novel-to-video/src/services/StoryboardService.ts
plugins/official/novel-to-video/src/services/ResourceService.ts
plugins/official/novel-to-video/src/services/WorkflowExecutor.ts  ← 新增视频生成调用
```

---

## 四、验收标准

### 功能验收
- [ ] callModel({ model: 'sora-2', category: 'video-generation', input }) 成功
- [ ] Settings 切换 Provider 后，插件自动路由
- [ ] N8N 工作流 Stage 1-4 + Stage 2.5 完整执行

### 代码验收
- [ ] `providers/` 目录不存在于插件中
- [ ] 搜索 `JiekouCustomAdapter` 返回 0 结果
- [ ] 搜索 `providerId` 在 default-config.json 返回 0 结果
- [ ] `AsyncPollingAdapter.ts` 文件存在

### 质量验收
- [ ] npm run build 成功
- [ ] npm run lint 无错误
- [ ] npm test 全部通过

---

## 五、测试准备计划（优先于代码修改）

> **原则**：先准备好测试项目和内容，代码修改后必须通过测试验证

### 5.1 现有测试覆盖分析

#### APIManager 测试现状

| 覆盖区域 | 测试文件 | 测试数 | 覆盖率 |
|---------|---------|--------|--------|
| Provider CRUD | APIManager.test.ts | 38 | 95% ✅ |
| IPC 通道 | api-model.ipc.test.ts | 18 | 90% ✅ |
| callT8StarImage() | ❌ 无 | 0 | 0% ⚠️ |
| callT8StarVideo() | ❌ 无 | 0 | 0% ⚠️ |
| pollT8StarVideoStatus() | ❌ 无 | 0 | 0% ⚠️ |
| ProviderRouter/Registry/Hub | ❌ 无 | 0 | 0% ⚠️ |

**估计总覆盖率**：~24%

#### Novel-to-Video 测试现状

| 测试文件 | 行数 | 覆盖内容 |
|---------|------|---------|
| workflow.test.ts | 364 | 5阶段工作流执行、Gate机制 ✅ |
| phase7-baseline.test.ts | 517 | 基准快照、数据结构验证 ✅ |
| NovelVideoAssetHelper.test.ts | 388 | 资产CRUD、性能测试 ✅ |
| workflow.ipc.test.ts | 181 | 工作流IPC通道 ✅ |

**缺失覆盖**：
- ❌ ChapterService 单元测试
- ❌ NovelVideoAPIService 单元测试
- ❌ ResourceService 单元测试
- ❌ StoryboardService 单元测试
- ❌ VoiceoverService 完全未覆盖
- ❌ WorkflowExecutor.executeStage4 视频生成

### 5.2 V0.4.0 架构测试计划

#### 5.2.1 新增测试文件清单

```
tests/
├── unit/
│   ├── services/
│   │   └── APIManager.test.ts  ← 扩展，添加 callModel() 测试
│   └── adapters/               ← 新增目录
│       ├── BaseAdapter.test.ts
│       ├── OpenAICompatibleAdapter.test.ts
│       ├── AsyncPollingAdapter.test.ts
│       └── ComfyUIWorkflowAdapter.test.ts
│
├── integration/
│   ├── adapters/               ← 新增目录
│   │   └── adapter-routing.test.ts
│   └── novel-video/            ← 新增目录
│       └── stage4-video-generation.test.ts
│
└── snapshots/
    └── phase7-baseline/        ← 更新
        └── output-stage4.json  ← 新增（含 videoSegments）
```

#### 5.2.2 测试用例设计

**A. APIManager.callModel() 测试**

```typescript
// tests/unit/services/APIManager.test.ts - 新增部分

describe('callModel', () => {
  // 路由测试
  it('应该根据模型名称路由到正确的Provider', async () => {
    // 注册两个Provider支持同模型，验证优先级路由
  });

  it('应该找不到Provider时抛出明确错误', async () => {
    // model: 'unknown-model' → Error('未找到支持模型...')
  });

  it('应该根据providerId直接调用指定Provider', async () => {
    // 绕过模型路由，直接使用指定Provider
  });

  // Adapter选择测试
  it('应该根据apiFormat选择OpenAICompatibleAdapter', async () => {
    // apiFormat: 'openai-compatible' → OpenAICompatibleAdapter
  });

  it('应该根据apiFormat选择AsyncPollingAdapter', async () => {
    // apiFormat: 'async-polling' → AsyncPollingAdapter
  });

  it('应该根据apiFormat选择ComfyUIWorkflowAdapter', async () => {
    // apiFormat: 'comfyui-workflow' → ComfyUIWorkflowAdapter
  });

  // 错误处理测试
  it('应该处理Adapter调用失败', async () => {
    // Adapter.callAPI() 抛出错误 → 正确传播
  });
});
```

**B. Adapter 单元测试**

```typescript
// tests/unit/adapters/AsyncPollingAdapter.test.ts

describe('AsyncPollingAdapter', () => {
  // 模型名称映射测试
  it('应该正确映射sora-2到sora-2-video-reverse', () => {
    // getEndpointByModel('sora-2') === '.../sora-2-video-reverse'
  });

  it('应该对未知模型返回原名', () => {
    // getEndpointByModel('custom-model') === '.../custom-model'
  });

  // API调用测试（mock fetch）
  it('应该成功提交异步任务', async () => {
    // 返回 { task_id: '...' }
  });

  it('应该成功轮询任务状态', async () => {
    // PROCESSING → PROCESSING → SUCCEED + result
  });

  it('应该处理轮询超时', async () => {
    // fake timers + 60次轮询后超时
  });

  it('应该处理任务失败状态', async () => {
    // 返回 FAILED → 抛出错误
  });
});

// tests/unit/adapters/OpenAICompatibleAdapter.test.ts

describe('OpenAICompatibleAdapter', () => {
  // LLM调用测试
  it('应该正确构建chat/completions请求', async () => {
    // 验证请求体结构
  });

  it('应该正确解析LLM响应', async () => {
    // 返回 { text: '...' }
  });

  // 图像生成测试
  it('应该正确调用图像生成API', async () => {
    // 返回 { imageUrl: '...' }
  });

  // 视频生成测试
  it('应该正确调用视频生成API', async () => {
    // 返回 { videoUrl: '...', taskId: '...' }
  });
});
```

**C. Stage 4 视频生成测试**

```typescript
// tests/integration/novel-video/stage4-video-generation.test.ts

describe('Stage 4 视频生成', () => {
  it('应该生成分镜图片和视频', async () => {
    // executeStage4() → { storyboardImages: [...], videoSegments: [...] }
  });

  it('应该在无分镜输出时失败', async () => {
    // stage3Output 不存在 → Error
  });

  it('应该正确调用generateStoryboardVideo', async () => {
    // 验证ResourceService.generateStoryboardVideo被调用
  });

  it('应该更新阀门检查包含videoSegments', async () => {
    // checkGateCondition('stage4') 检查 videoSegments
  });
});
```

**D. Adapter 路由集成测试**

```typescript
// tests/integration/adapters/adapter-routing.test.ts

describe('Adapter路由集成', () => {
  beforeEach(async () => {
    // 注册多个不同apiFormat的Provider
    await apiManager.addProvider({
      id: 'jiekou-ai',
      apiFormat: 'async-polling',
      models: ['sora-2', 'z-image-turbo']
    });
    await apiManager.addProvider({
      id: 't8star',
      apiFormat: 'openai-compatible',
      models: ['sora-2', 'nano-banana']
    });
    await apiManager.addProvider({
      id: 'local-comfyui',
      apiFormat: 'comfyui-workflow',
      models: ['sdxl-local']
    });
  });

  it('sora-2应该路由到最高优先级Provider', async () => {
    // 验证选择了优先级高的Provider
  });

  it('切换Provider后应该使用新配置', async () => {
    // 禁用jiekou-ai → 自动切换到t8star
  });

  it('本地ComfyUI模型应该使用ComfyUIWorkflowAdapter', async () => {
    // sdxl-local → ComfyUIWorkflowAdapter
  });
});
```

### 5.3 基准快照更新

**更新 `tests/snapshots/phase7-baseline/`**：

```json
// output-stage4.json - 新增
{
  "description": "Stage 4完整输出结构",
  "expectedOutputs": {
    "storyboardImages": [
      {
        "id": "storyboard-image-1",
        "prompt": "scene description...",
        "referenceImages": [],
        "filePath": "/path/to/image.png"
      }
    ],
    "videoSegments": [
      {
        "id": "video-segment-1",
        "storyboardId": "storyboard-1",
        "prompt": "video prompt...",
        "filePath": "/path/to/video.mp4",
        "duration": 10
      }
    ]
  },
  "gateConditions": ["storyboardImages", "videoSegments"]
}
```

### 5.4 测试执行顺序

```
步骤 1: 运行现有测试确认基线
   npm test
   → 确保所有测试通过后再开始修改

步骤 2: 创建新测试文件（先编写测试）
   ├── tests/unit/adapters/*.test.ts
   ├── tests/integration/adapters/adapter-routing.test.ts
   └── tests/integration/novel-video/stage4-video-generation.test.ts

   → 测试初始状态应为 FAIL（功能未实现）

步骤 3: 实施代码修改（按 P0 → P1 顺序）
   → 每完成一项修改，对应测试应变为 PASS

步骤 4: 最终验证
   npm test                # 所有测试通过
   npm run test:coverage   # 覆盖率达标
   npm run build           # 构建成功
   npm run lint            # 无错误
```

### 5.5 验收标准（测试维度）

#### 功能验收测试
- [ ] `APIManager.callModel()` 路由测试通过
- [ ] `AsyncPollingAdapter` 轮询测试通过（含超时）
- [ ] `OpenAICompatibleAdapter` API调用测试通过
- [ ] `ComfyUIWorkflowAdapter` 工作流测试通过
- [ ] `Stage 4 视频生成` 集成测试通过
- [ ] `Adapter路由` 集成测试通过

#### 覆盖率目标
- [ ] APIManager.ts 覆盖率 ≥ 60%（从24%提升）
- [ ] 新增 Adapter 文件覆盖率 ≥ 80%
- [ ] WorkflowExecutor.ts 覆盖率 ≥ 70%

#### 回归验证
- [ ] 现有 38 个 APIManager 单元测试全部通过
- [ ] 现有 18 个 api-model IPC 测试全部通过
- [ ] 现有 workflow.test.ts 全部通过
- [ ] 现有 phase7-baseline.test.ts 全部通过

---

## 六、下一步行动

1. **用户确认**：测试计划是否符合预期？
2. **创建测试文件**：先编写测试（预期 FAIL）
3. **实施代码修改**：按 P0 → P1 顺序执行
4. **验证测试通过**：所有测试变为 PASS
